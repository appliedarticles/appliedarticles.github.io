<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>Face Detection using OpenCV - Himanshu Shekhar</title>
	<meta name="description" content="">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta property="og:image" content="">
	<link rel="shortcut icon" href="/assets/img/favicon/favicon.ico" type="image/x-icon">
	<link rel="apple-touch-icon" href="/assets/img/favicon/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicon/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicon/apple-touch-icon-114x114.png">
	<!-- Chrome, Firefox OS and Opera -->
	<meta name="theme-color" content="#311e3e">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#311e3e">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#311e3e">
	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=Montserrat:300,400,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700" rel="stylesheet">
	<!-- Font Awesome -->
	<link rel="stylesheet" href="/assets/fonts/font-awesome/css/font-awesome.min.css">
	<!-- Styles -->
	<link rel="stylesheet" href="/assets/css/main.css">
</head>

<body>
  <div class="flex-container">
  <header class="main-header">
  <div class="wrapper">
    <div class="header-flex">
      <div class="menu-icon-container">
        <span class="menu-icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
      </div>
      <nav class="main-nav">
        <span class="menu-icon-close"><i class="fa fa-times" aria-hidden="true"></i></span>
        <ul>
          <li><a href="/">Blog</a></li>
          <li><a href="/about">About</a></li>
          <li><a href="/projects">Projects</a></li>
          <li><a href="/resources">Resources</a></li>

        </ul>
      </nav>
      <p class="logo"><a href="/">Himanshu Shekhar</a></p>
      <div class="search-icon-container">
        <span class="search-icon"><a><i class="fa fa-search" aria-hidden="true"></i></a></span>
      </div>
    </div>
  </div>
</header> <!-- End Header -->

  <article class="article-page">
    <div class="page-image">
      <div class="cover-image" style="background: url(/assets/img/fac.jpg) center no-repeat; background-size: cover;"></div>
    </div>
    <div class="wrapper">
      <div class="page-content">
        <div class="header-page">
          <h1 class="page-title">Face Detection using OpenCV</h1>
          <div class="page-date"><time datetime=""></time></div>
        </div>
        <p><strong><em>Face detection</em></strong> is a computer technology being used in a variety of applications that identifies human faces in digital images.
Face detection can be regarded as a specific case of object detection.<br />
Face-detection algorithms focus on the detection of frontal human faces. It is analogous to image detection in which the image of a person is matched bit by bit. Image matches with the image stores in database. Any facial feature changes in the database will invalidate the matching process.</p>

<p><img src="/assets/img/face.png" alt="Plot" class="img-responsive" /></p>

<h3 id="application">Application</h3>
<ul>
  <li>Facial recognition</li>
  <li>Facial motion capture</li>
  <li>Biometrics</li>
  <li>Photography</li>
</ul>

<h3 id="opencv-classifier">OpenCV Classifier</h3>
<p>A computer program that decides whether an image is a positive image (face image) or negative image (non-face image) is called a classifier. A classifier is trained on hundreds of thousands of face and non-face images to learn how to classify a new image correctly. OpenCV provides us with two pre-trained and ready to be used for face detection classifiers:</p>

<ul>
  <li><strong><em>Haar Classifier</em></strong></li>
  <li><strong><em>LBP Classifier</em></strong></li>
</ul>

<p>Both of these classifiers process images in gray scales, basically because we don’t need color information to decide if a picture has a face or not. As these are pre-trained in OpenCV, their learned knowledge files also come bundled with OpenCV opencv/data/.</p>

<p>To run a classifier, we need to load the knowledge files first, as if it had no knowledge.
Each file starts with the name of the classifier it belongs to. For example, a Haar cascade classifier starts off as <em>haarcascade_frontalface_alt.xml</em>.</p>

<p>These are the two types of classifiers we will be using to analyze image.</p>

<h3 id="haar-cascade-classifier">HAAR Cascade Classifier</h3>

<p>The Haar Classifier is a machine learning based approach, an algorithm proposed by Paul Viola and improved by Rainer Lienhart; which are trained from many positive images (with faces) and negatives images (without faces). It starts by extracting Haar features from each image as shown by the windows below:</p>

<p><img src="/assets/img/haarfeatures.png" alt="Plot" class="img-responsive" /></p>

<p>Each window is placed on the picture to calculate a single feature. This feature is a single value obtained by subtracting the sum of pixels under the white part of the window from the sum of the pixels under the black part of the window.<br />
Now, all possible sizes of each window are placed on all possible locations of each image to calculate plenty of features.</p>

<h3 id="lbp-cascade-classifier">LBP Cascade Classifier</h3>

<p>As any other classifier, the Local Binary Patterns, or LBP in short, also needs to be trained on hundreds of images. Local binary patterns (LBP) is a type of visual descriptor used for classification in computer vision.<br />
It has since been found to be a powerful feature for texture classification; it has further been determined that when LBP is combined with the Histogram of oriented gradients (HOG) descriptor, it improves the detection performance considerably on some datasets.<br />
So, LBP features are extracted to form a feature vector that classifies a face from a non-face.</p>

<p><strong><em>Concept</em></strong></p>
<ul>
  <li>Each training image is divided into some blocks as shown in the picture below.</li>
  <li>For each block, LBP looks at 9 pixels (3×3 window) at a time, and with a particular interest in the pixel located in the center of the window.</li>
  <li>Then, it compares the central pixel value with every neighbor’s pixel value under the 3×3 window. For each neighbor pixel that is greater than or equal to the center pixel, it sets its value to 1, and for the others, it sets them to 0.</li>
  <li>After that, it reads the updated pixel values (which can be either 0 or 1) in a clockwise order and forms a binary number. Next, it converts the binary number into a decimal number, and that decimal number is the new value of the center pixel. We do this for every pixel in a block.</li>
  <li>Then, it converts each block values into a histogram, so now we have gotten one histogram for each block in an image.</li>
  <li>Finally, it concatenates these block histograms to form a one feature vector for one image, which contains all the features we are interested. So, this is how we extract LBP features from a picture.</li>
</ul>

<h3 id="implementation">Implementation</h3>

<p>Importing required libraries.<br />
Importing time library for speed comparisons of both classifiers.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>
<p>When we load an image using OpenCV, it loads it into BGR color space by default. To show the colored image using matplotlib we have to convert it to RGB space. So, we need to define a function which does this operation.</p>

<p><em>cv2.cvtColor</em> is an OpenCV function to convert images to different color spaces. It takes as input an image to transform, and a color space code (like cv2.COLOR_BGR2RGB) and returns the processed image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">convertToRGB</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
</code></pre></div></div>
<p>Next, we define a function <em>detect_faces()</em> which takes 3 arguments.</p>

<ul>
  <li><strong><em>f_cascade</em></strong>: It defines the type of Cascade Classifier.</li>
  <li><strong><em>colored_img</em></strong>: It is the input image that we want to test.</li>
  <li><strong><em>scaleFactor</em></strong>: This function compensates a false perception in size that occurs when one face appears to be bigger than the other simply because it is closer to the camera.
<strong><em>cv2.cvtColor</em></strong> is an OpenCV function to convert the test image to gray image as opencv face detector expects gray images.</li>
</ul>

<p><em>detectMultiScale(image, scaleFactor, minNeighbors)</em>: This is a general function to detect objects, in this case, it’ll detect faces since we called in the face cascade. If it finds a face, it returns a list of positions of said face in the form “<em>Rect(x,y,w,h)</em>.”, if not, then returns “None”.</p>

<ul>
  <li><strong><em>image</em></strong>: Converted input image is the grayscale image.</li>
  <li><strong><em>minNeighbors</em></strong>: This is a detection algorithm that uses a moving window to detect objects, it does so by defining how many objects are found near the current one before it can declare the face found.</li>
</ul>

<p>Once we have the list of recognized faces, we can loop over them and draw a rectangle on the copy of the image and return the modified copy of the picture.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">detect_faces</span><span class="p">(</span><span class="n">f_cascade</span><span class="p">,</span> <span class="n">colored_img</span><span class="p">,</span> <span class="n">scaleFactor</span> <span class="o">=</span> <span class="mf">1.1</span><span class="p">):</span>
 <span class="c1">#just making a copy of image passed, so that passed image is not changed
</span> <span class="n">img_copy</span> <span class="o">=</span> <span class="n">colored_img</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>          

 <span class="c1">#convert the test image to gray image as opencv face detector expects gray images
</span> <span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img_copy</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>          

 <span class="c1">#let's detect multiscale (some images may be closer to camera than others) images
</span> <span class="n">faces</span> <span class="o">=</span> <span class="n">f_cascade</span><span class="o">.</span><span class="n">detectMultiScale</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span> <span class="n">scaleFactor</span><span class="o">=</span><span class="n">scaleFactor</span><span class="p">,</span> <span class="n">minNeighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>          

 <span class="c1">#go over list of faces and draw them as rectangles on original colored img
</span> <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="ow">in</span> <span class="n">faces</span><span class="p">:</span>
      <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img_copy</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">,</span> <span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>              

 <span class="k">return</span> <span class="n">img_copy</span>
</code></pre></div></div>

<h3 id="opencv-haar-cascade-classifier">OpenCV HAAR Cascade Classifier</h3>

<p>Here we will deal with detection. OpenCV already contains many pre-trained classifiers for face, eyes, smiles, etc. Those XML files are stored in the opencv/data/haarcascades/ folder.<br />
We need to load the required XML classifiers and then pass this as an argument in <em>detect_faces()</em> function in order to test the new image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#load cascade classifier training file for haarcascade
</span><span class="n">haar_face_cascade</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CascadeClassifier</span><span class="p">(</span><span class="s">'data/haarcascade_frontalface_alt.xml'</span><span class="p">)</span>
</code></pre></div></div>
<h3 id="test-1">Test 1</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#load another image
</span><span class="n">test2</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s">'data/a.jpg'</span><span class="p">)</span>  

<span class="c1">#call our function to detect faces
</span><span class="n">faces_detected_img</span> <span class="o">=</span> <span class="n">detect_faces</span><span class="p">(</span><span class="n">haar_face_cascade</span><span class="p">,</span> <span class="n">test2</span><span class="p">)</span>  

<span class="c1">#convert image to RGB and show image
</span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">convertToRGB</span><span class="p">(</span><span class="n">faces_detected_img</span><span class="p">))</span>
</code></pre></div></div>
<p><img src="/assets/img/t1.png" alt="Plot" class="img-responsive" /></p>

<h3 id="test-2---dealing-with-false-positive">Test 2 - Dealing with False Positive</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#load another image
</span><span class="n">test2</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s">'data/b.jpg'</span><span class="p">)</span>  

<span class="c1">#call our function to detect faces
</span><span class="n">faces_detected_img</span> <span class="o">=</span> <span class="n">detect_faces</span><span class="p">(</span><span class="n">haar_face_cascade</span><span class="p">,</span> <span class="n">test2</span><span class="p">)</span>  

<span class="c1">#convert image to RGB and show image
</span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">convertToRGB</span><span class="p">(</span><span class="n">faces_detected_img</span><span class="p">))</span>
</code></pre></div></div>
<p><img src="/assets/img/t2.png" alt="Plot" class="img-responsive" /></p>

<p>We got one false positives.</p>

<p>A simple tweak to the scale factor compensates for this so can move that parameter around. For example, scaleFactor=1.2 improved the results.</p>

<h3 id="test-2-with-scalefactor12">Test 2 with scaleFactor=1.2</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#load another image
</span><span class="n">test2</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s">'data/b.jpg'</span><span class="p">)</span>  

<span class="c1">#call our function to detect faces
</span><span class="n">faces_detected_img</span> <span class="o">=</span> <span class="n">detect_faces</span><span class="p">(</span><span class="n">haar_face_cascade</span><span class="p">,</span> <span class="n">test2</span><span class="p">,</span> <span class="n">scaleFactor</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>  

<span class="c1">#convert image to RGB and show image
</span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">convertToRGB</span><span class="p">(</span><span class="n">faces_detected_img</span><span class="p">))</span>
</code></pre></div></div>
<p><img src="/assets/img/t3.png" alt="Plot" class="img-responsive" /></p>

<p>12 people detected</p>

<h3 id="opencv-lbp-cascade-classifier">OpenCV LBP Cascade Classifier</h3>

<p>XML training files for LBP cascade are stored in the opencv/data/lbpcascades/ folder. We just need to pass this LBP classifier to the same function and then test new data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#load cascade classifier training file for lbpcascade
</span><span class="n">lbp_face_cascade</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CascadeClassifier</span><span class="p">(</span><span class="s">'data/lbpcascade_frontalface.xml'</span><span class="p">)</span>  

<span class="c1">#load test image
</span><span class="n">test2</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s">'data/a.jpg'</span><span class="p">)</span>

<span class="c1">#call our function to detect faces
</span><span class="n">faces_detected_img</span> <span class="o">=</span> <span class="n">detect_faces</span><span class="p">(</span><span class="n">lbp_face_cascade</span><span class="p">,</span> <span class="n">test2</span><span class="p">)</span>  

<span class="c1">#convert image to RGB and show image
</span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">convertToRGB</span><span class="p">(</span><span class="n">faces_detected_img</span><span class="p">))</span>
</code></pre></div></div>
<p><img src="/assets/img/t1.png" alt="Plot" class="img-responsive" /></p>

<h3 id="comparative-analysis-of-haar-vs-lbp">Comparative analysis of HAAR vs. LBP</h3>

<p>Let’s compare both Haar and LBP on two test images to see accuracy and time delay of each.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#load cascade classifier training file for haarcascade
</span><span class="n">haar_face_cascade</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CascadeClassifier</span><span class="p">(</span><span class="s">'data/haarcascade_frontalface_alt.xml'</span><span class="p">)</span>
<span class="c1">#load cascade classifier training file for lbpcascade
</span><span class="n">lbp_face_cascade</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CascadeClassifier</span><span class="p">(</span><span class="s">'data/lbpcascade_frontalface.xml'</span><span class="p">)</span>  

<span class="c1">#load test image2
</span><span class="n">test</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s">'data/c.jpg'</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#------------HAAR-----------
#note time before detection
</span><span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  

<span class="c1">#call our function to detect faces
</span><span class="n">haar_detected_img</span> <span class="o">=</span> <span class="n">detect_faces</span><span class="p">(</span><span class="n">haar_face_cascade</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>  

<span class="c1">#note time after detection
</span><span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="c1">#calculate time difference
</span><span class="n">dt1</span> <span class="o">=</span> <span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span>
<span class="c1">#print the time difference
</span>
<span class="c1">#------------LBP-----------
#note time before detection
</span><span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1">#call our function to detect faces
</span><span class="n">lbp_detected_img</span> <span class="o">=</span> <span class="n">detect_faces</span><span class="p">(</span><span class="n">lbp_face_cascade</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>  

<span class="c1">#note time after detection
</span><span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="c1">#calculate time difference
</span><span class="n">dt2</span> <span class="o">=</span> <span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span>
<span class="c1">#print the time difference
</span>
<span class="c1">#create a figure of 2 plots (one for Haar and one for LBP)
</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>  

<span class="c1">#show Haar image
</span><span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Haar Detection time: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">dt1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span> <span class="o">+</span> <span class="s">' secs'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">convertToRGB</span><span class="p">(</span><span class="n">haar_detected_img</span><span class="p">))</span>  

<span class="c1">#show LBP image
</span><span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'LBP Detection time: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">dt2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span> <span class="o">+</span> <span class="s">' secs'</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">convertToRGB</span><span class="p">(</span><span class="n">lbp_detected_img</span><span class="p">))</span>  
</code></pre></div></div>
<p><img src="/assets/img/t4.png" alt="Plot" class="img-responsive" /></p>

<h3 id="observation">Observation</h3>

<ul>
  <li><strong><em>Accuracy</em></strong>: <em>HAAR</em> detected more faces and than <em>LBP</em>.</li>
  <li><strong><em>Speed</em></strong>: <em>LBP</em> was significantly faster than <em>HAAR</em>.</li>
</ul>

<blockquote>
  <p><em>In case if you found something useful to add to this article or you found a bug in the code or would like to improve some points mentioned, feel free to write it down in the comments. Hope you found something useful here.</em></p>
</blockquote>

        <div class="page-footer">
          <div class="page-tag">
            <span>Tags:</span>
            
            <a href="/tags#CNN" class="tag">| CNN</a>
            
          </div><!-- End Tags -->
          <div class="page-share">
            <span>Share:</span>
            <a href="https://twitter.com/intent/tweet?text=Face Detection using OpenCV&url=http://localhost:4000/projects/face-detection-using-opencv/" title="Share on Twitter" rel="nofollow" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
            <a href="https://facebook.com/sharer.php?u=http://localhost:4000/projects/face-detection-using-opencv/" title="Share on Facebook" rel="nofollow" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
            <a href="https://plus.google.com/share?url=http://localhost:4000/projects/face-detection-using-opencv/" title="Share on Google+" rel="nofollow" target="_blank"><i class="fa fa-google" aria-hidden="true"></i></a>
          </div><!-- End Share -->
        </div>
        <!--<section class="author-box">
  <img src="/assets/img/pic.jpeg" alt="Himanshu Shekhar" class="author-img">
  <div class="author-desc">
    <h2>Himanshu Shekhar</h2>
    <p></p>
    <ul>
      
        <li class="email"><a href="mailto:hshekhar0@gmail.com"><i class="fa fa-envelope-o"></i></a></li>
      
      
        <li class="phone"><a href="tel:044 825 5523"><i class="fa fa-phone" aria-hidden="true"></i></a></li>
      
      
        <li class="website"><a href="http://hshekhar.in" target="_blank"><i class="fa fa-globe"></i></a></li>
      
      
        <li class="twitter"><a href="https://twitter.com/shekhartz" target="_blank"><i class="fa fa-twitter"></i></a></li>
      
    </ul>
  </div>
</section>
-->
        <div class="recent-box">
  <h2 class="recent-title">Recent post</h2>
  <div class="recent-list">
    
      
        <a href="/python-tools-list-for-nlp/" class="recent-item" style="background: url(/assets/img/nlp.png) center no-repeat; background-size: cover;"><span>Python Tools List for Natural Language Processing</span></a>
      
    
      
        <a href="/demystifying-quantum-machine-learning/" class="recent-item" style="background: url(/assets/img/qml.jpg) center no-repeat; background-size: cover;"><span>Demystifying Quantum Machine Learning</span></a>
      
    
      
        <a href="/crisp-dm/" class="recent-item" style="background: url(/assets/img/crisp.jpg) center no-repeat; background-size: cover;"><span>CRoss-Industry Standard Process for Data Mining</span></a>
      
    
      
        <a href="/ways-to-use-convnet/" class="recent-item" style="background: url(/assets/img/cnn.png) center no-repeat; background-size: cover;"><span>How to use ConvNets in different ways - a brief analogy</span></a>
      
    
  </div>
</div> <!-- End Recent-Box -->

        <div class="newsletter" id="mc_embed_signup">
  <h2 class="newsletter-title">Newsletter</h2>
  <div class="form-container">
    <p>Subscribe here to get our latest updates</p>
    <form action="//" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
      <label class="screen-reader-text" for="mce-EMAIL">Email Address</label>
      <div class="newsletter-box" id="mc_embed_signup_scroll">
        <input type="email" name="EMAIL" placeholder="Email address" class="email-input" id="mce-EMAIL" required>
        <input type="submit" value="Subscribe" name="subscribe" class="subscribe-btn" id="mc-embedded-subscribe">
      </div>
    </form>
  </div>
</div> <!-- End Newsletter -->

        <section class="comment-area">
  <div class="comment-wrapper">
    
    <div id="disqus_thread" class="article-comments"></div>
    <script>
      (function() {
          var d = document, s = d.createElement('script');
          s.src = '//hshekhar.disqus.com/embed.js';
          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
      })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    
  </div>
</section> <!-- End Comment Area -->

      </div>
    </div> <!-- End Wrapper -->
  </article>
  <div class="search-box">
  <div class="wrapper">
    <div class="search-grid">
      <form class="search-form">
        <div id="search-container">
          <input type="text" id="search-input" class="search" placeholder="Search">
        </div>
      </form>
      <ul id="results-container" class="results-search"></ul>
      <div class="icon-close-container">
        <span class="search-icon-close"><i class="fa fa-times" aria-hidden="true"></i></span>
      </div>
    </div>
  </div>
</div>

  <footer class="main-footer">
  <div class="copyright">
    <p>2020 &copy; Himanshu Shekhar</p>
  </div>
</footer> <!-- End Footer -->

</div>

  <!-- JS -->
<script src="/assets/js/jquery-3.2.1.min.js"></script>
<script src="/assets/js/jekyll-search.js"></script>
<script>
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('results-container'),
    json: '/search.json',
    searchResultTemplate: '<li><a href="{url}" title="{desc}">{title}</a></li>',
    noResultsText: 'No results found',
    fuzzy: false,
    exclude: ['Welcome']
  });
</script>
<script src="/assets/js/main.js"></script>

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-133548690-1', 'auto');
  ga('send', 'pageview');
</script> <!-- End Analytics -->

</body>
</html>
